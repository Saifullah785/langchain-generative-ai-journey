{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmcXUR3mF0oxhf3/QU7dz3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saifullah785/langchain-generative-ai-journey/blob/main/Lecture_15_tool_calling_in_langchain/Lecture_15_tool_calling_in_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries for LangChain, HuggingFace integration, and requests.\n",
        "!pip install -q langchain_huggingface langchain-core requests"
      ],
      "metadata": {
        "id": "B4JfQkbMIvjF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "02fqYMzCHfat"
      },
      "outputs": [],
      "source": [
        "# Import necessary classes and functions from LangChain and requests library.\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import userdata from google.colab to access secrets.\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the Hugging Face API key from Colab secrets, named \"hf_token\".\n",
        "hf_api_key = userdata.get(\"hf_token\")"
      ],
      "metadata": {
        "id": "apc8AbESJCvJ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the HuggingFaceEndpoint with the Llama-3.1-8B-Instruct model for text generation.\n",
        "llm = HuggingFaceEndpoint(\n",
        "    # repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\", # Example of a commented-out model\n",
        "    repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
        ")\n",
        "\n",
        "# Wrap the endpoint in a ChatHuggingFace object for chat-style interaction.\n",
        "model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "EmBn_7IEI3qK"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tool function using the @tool decorator.\n",
        "# This function takes two integers, a and b, and returns their product.\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "  \"\"\"Given 2 numbers a and b this tool returns their product\"\"\"\n",
        "  return a * b"
      ],
      "metadata": {
        "id": "kb9clY3AJ0wy"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the multiply tool with inputs a=2 and b=3 and print the result.\n",
        "print(multiply.invoke({\"a\": 2, \"b\": 3}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V57UONsvKGha",
        "outputId": "241d3993-2ec7-4330-b6c0-7e757b53747d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access and display the name of the multiply tool.\n",
        "multiply.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6K4z7qGKKLor",
        "outputId": "fff14001-aa86-435f-9334-8742d8b2f653"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'multiply'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access and display the description of the multiply tool.\n",
        "multiply.description"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3ze5h351KOW6",
        "outputId": "b223a5eb-99d2-41a0-f199-a26e99a745d0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Given 2 numbers a and b this tool returns their product'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access and display the arguments expected by the multiply tool.\n",
        "multiply.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azJpTrdxKSBa",
        "outputId": "f33bad50-7db4-4139-c39b-361ca9fb2c84"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': {'title': 'A', 'type': 'integer'},\n",
              " 'b': {'title': 'B', 'type': 'integer'}}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the chat model with the input 'hi' and display the response.\n",
        "model.invoke('hi')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_7fSZpkKjv7",
        "outputId": "3647a393-bc9e-41b1-d90d-6c55bd197f68"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\" Hello! How can I help you today? If you have any questions about a specific topic or just want to chat, feel free to ask. I'm here to provide information and engage in a conversation with you. ðŸ˜Š\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 9, 'total_tokens': 56}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--14f1d46f-4102-4d59-a2bd-ec0ac7737b1a-0', usage_metadata={'input_tokens': 9, 'output_tokens': 47, 'total_tokens': 56})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bind the multiply tool to the chat model, creating a new model instance that can use the tool.\n",
        "llm_with_tools = model.bind_tools([multiply])"
      ],
      "metadata": {
        "id": "DypNamepKu3U"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how to invoke the model with tools (currently commented out).\n",
        "# llm_with_tools.invoke('hi how are you')"
      ],
      "metadata": {
        "id": "JB8Hozu9KU4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f916584-80bf-44c4-e202-4f05f1228ed9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=' Hello! I\\'m an artificial intelligence and do not have feelings, but I\\'m here to help you. Is there anything you would like to multiply? I can do calculations for you using the \"multiply\" function.\\n\\nTo use the \"multiply\" function, you need to provide me with two numbers to multiply. Here is the format for using the function:\\n\\n{\\n  \"function\": {\\n    \"name\": \"multiply\",\\n    \"parameters\": {\\n      \"a\": <number 1>,\\n      \"b\": <number 2>\\n    }\\n  }\\n}\\n\\nYou can replace <number 1> and <number 2> with the two numbers you would like to multiply. For example, if you want to multiply 3 and 5, the format would look like this:\\n\\n{\\n  \"function\": {\\n    \"name\": \"multiply\",\\n    \"parameters\": {\\n      \"a\": 3,\\n      \"b\": 5\\n    }\\n  }\\n}\\n\\nI hope that helps! Let me know if you have any questions or if you would like to use the \"multiply\" function.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 258, 'prompt_tokens': 173, 'total_tokens': 431}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--f0cdd079-7de4-49bb-bc78-da099f8b699e-0', usage_metadata={'input_tokens': 173, 'output_tokens': 258, 'total_tokens': 431})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the model with tools to see if it suggests using the multiply tool for the query \"can you multiply 3 with 10\".\n",
        "result = llm_with_tools.invoke('can you multiply 3 with 10')"
      ],
      "metadata": {
        "id": "8GJkOFd61oC7"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the tool calls generated by the model's response.\n",
        "result.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Arheq1X2C4N",
        "outputId": "9c2b478e-9447-42c5-fa40-8ab22a6a4e50"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f8b06e9"
      },
      "source": [
        "# Create a HumanMessage object with the query \"can you multiply 3 with 1000\".\n",
        "query = HumanMessage('can you multiply 3 with 1000')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list containing the initial query message.\n",
        "messages = [query]"
      ],
      "metadata": {
        "id": "7oak6UdUstg8"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the current list of messages.\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm-o4hCnsyQf",
        "outputId": "8f30b8d5-0378-4fb6-e3d1-db5989488eed"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='can you multiply 3 with 1000', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the model with the messages and display the content of the response.\n",
        "llm_with_tools.invoke(messages).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CGKExLir4awR",
        "outputId": "35498c7e-7b94-4a5c-ff46-9df52807fc4a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nSo, 3 multiplied by 1000 is equal to 3000.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the model with the messages and store the response in the 'result' variable.\n",
        "result = llm_with_tools.invoke(messages)"
      ],
      "metadata": {
        "id": "aQ-SsdVys3me"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the model's response.\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU48uQZmzzMT",
        "outputId": "07d34660-f5d0-4b79-9be9-c0a5852e8469"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=' Sure, I can help you with that. To multiply 3 with 1000, I will use the \"multiply\" function that is available to me. Here is the function call with the appropriate parameters:\\n\\nmultiply(a: 3, b: 1000)\\n\\nThis will return the product of 3 and 1000. Let me calculate the result for you.\\n\\nThe product of 3 and 1000 is 3000.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 181, 'total_tokens': 291}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--634d9248-82c2-4936-8de7-66c9adf5a120-0', usage_metadata={'input_tokens': 181, 'output_tokens': 110, 'total_tokens': 291})"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the content of the model's response.\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZYaT-Wwz2q5",
        "outputId": "31652e84-9f39-4ca1-ce86-38b81ec8fba6"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sure, I can help you with that. To multiply 3 with 1000, I will use the \"multiply\" function that is available to me. Here is the function call with the appropriate parameters:\n",
            "\n",
            "multiply(a: 3, b: 1000)\n",
            "\n",
            "This will return the product of 3 and 1000. Let me calculate the result for you.\n",
            "\n",
            "The product of 3 and 1000 is 3000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Append the model's response to the list of messages to continue the conversation history.\n",
        "messages.append(result)"
      ],
      "metadata": {
        "id": "PQvztBbptDkQ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the updated list of messages.\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkSk6xYjtHvV",
        "outputId": "33a015fa-dbb1-4476-bed3-8c3da297ec0e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='can you multiply 3 with 1000', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=' Sure, I can help you with that. To multiply 3 with 1000, I will use the \"multiply\" function that is available to me. Here is the function call with the appropriate parameters:\\n\\nmultiply(a: 3, b: 1000)\\n\\nThis will return the product of 3 and 1000. Let me calculate the result for you.\\n\\nThe product of 3 and 1000 is 3000.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 110, 'prompt_tokens': 181, 'total_tokens': 291}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--634d9248-82c2-4936-8de7-66c9adf5a120-0', usage_metadata={'input_tokens': 181, 'output_tokens': 110, 'total_tokens': 291})]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVj7ODKO56Ki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
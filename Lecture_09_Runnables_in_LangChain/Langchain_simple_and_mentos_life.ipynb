{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpp4cDPQj1bN0IL0RSf8fM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saifullah785/langchain-generative-ai-journey/blob/main/Lecture_09_Runnables_in_LangChain/Langchain_simple_and_mentos_life.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **langchain_simple_life**"
      ],
      "metadata": {
        "id": "wFAbo9_n0wRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random # Import the random module for generating random responses"
      ],
      "metadata": {
        "id": "V3jlnDRVlAF7"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "Dy05XVV0jed2"
      },
      "outputs": [],
      "source": [
        "class NakliLLM: # Define a simple mock LLM class\n",
        "\n",
        "  def __init__(self):\n",
        "    print('LLM created') # Print a message when an instance is created\n",
        "\n",
        "  def predict(self, prompt): # Define a predict method\n",
        "    # A list of predefined responses\n",
        "    response_list = [\n",
        "        'islambad is the capital of Pakistan',\n",
        "        'AI stand for Artificial Intelligence',\n",
        "        'ML stand for Machine Learning',\n",
        "        'DL stand for Deep Learning'\n",
        "\n",
        "    ]\n",
        "    return (random.choice(response_list)) # Return a random response from the list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = NakliLLM() # Create an instance of the NakliLLM class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFjDiEy1lOGV",
        "outputId": "0aff5d88-cc48-48bf-989c-f9d81fd940d0"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict('what is captical of pakistan') # Call the predict method with a prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3eGgmcUolYrs",
        "outputId": "114864f6-cc8c-4371-b238-49e32d281fa2"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ML stand for Machine Learning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NakliPromptTemplate: # Define a simple mock PromptTemplate class\n",
        "  def __init__(self, template, input_variables):\n",
        "    self.template = template # Store the template string\n",
        "    self.input_variables = input_variables # Store the list of input variables\n",
        "\n",
        "  def format(self, input_dict): # Define a format method to format the template\n",
        "    return self.template.format(**input_dict) # Use string formatting with the input dictionary"
      ],
      "metadata": {
        "id": "HXBvaC2ellut"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = NakliPromptTemplate( # Create an instance of NakliPromptTemplate\n",
        "    template = 'write a {length} poem about {topic}', # Define the template string\n",
        "    input_variables = ['length', 'topic'] # Define the input variables\n",
        ")"
      ],
      "metadata": {
        "id": "GwULwHhomqBv"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format({'length': 'short','topic':'pakistan'}) # Format the template with specific inputs"
      ],
      "metadata": {
        "id": "y6YHhseLm-xV"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = NakliLLM() # Create another instance of the NakliLLM class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddw-3UNmooTG",
        "outputId": "e82e04c3-d026-4ada-d866-efd65f5124f4"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.predict(prompt) # Call the predict method with the formatted prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ETj2o_iio3XM",
        "outputId": "69290f92-c2dc-42e5-a4d6-7c1e0abb4083"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI stand for Artificial Intelligence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NakliLLMChain: # Define a simple mock LLMChain class\n",
        "\n",
        "  def __init__(self, llm, prompt):\n",
        "    self.llm = llm # Store the LLM instance\n",
        "    self.prompt = prompt # Store the prompt template instance\n",
        "\n",
        "  def run(self, input_dict): # Define a run method to execute the chain\n",
        "    final_prompt = self.prompt.format(input_dict) # Format the prompt with the input dictionary\n",
        "    result = self.llm.predict(final_prompt) # Get the prediction from the LLM\n",
        "    return result # Return the result"
      ],
      "metadata": {
        "id": "qbGatTvSpNXx"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = NakliLLM() # Create another instance of the NakliLLM class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgOFh7N5pytp",
        "outputId": "10ba5b75-8c5a-4dab-d99c-1c74a9500e88"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = NakliLLMChain(llm, template) # Create an instance of NakliLLMChain with the LLM and template"
      ],
      "metadata": {
        "id": "1rsvUCVVp2OU"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run({'length':'short', 'topic':'pakistan'}) # Run the chain with specific inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "crR6LEFXp4_r",
        "outputId": "54f1e2fd-f0d1-4afb-b127-636868c2992e"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI stand for Artificial Intelligence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Langchain-mentos life**"
      ],
      "metadata": {
        "id": "4CqYN_Ho0zbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod # Import ABC and abstractmethod for creating abstract base classes"
      ],
      "metadata": {
        "id": "-fiQ9wRL1v5i"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Runnable(ABC): # Define an abstract base class called Runnable\n",
        "\n",
        "  @abstractmethod\n",
        "  def invoke(input_data): # Define an abstract method called invoke\n",
        "    pass"
      ],
      "metadata": {
        "id": "pkR3cQvD1vxA"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random # Import the random module\n",
        "\n",
        "class NakliLLM(Runnable): # Define NakliLLM inheriting from Runnable\n",
        "\n",
        "  def __init__(self):\n",
        "    print('LLM created') # Print a message when an instance is created\n",
        "\n",
        "  def invoke(self, prompt): # Implement the invoke method\n",
        "    response_list = [\n",
        "        'islamabad is the capital of Pakistan',\n",
        "        'PSL is a cricket league',\n",
        "        'AI stands for Artificial Intelligence'\n",
        "    ]\n",
        "\n",
        "    return {'response': random.choice(response_list)} # Return a dictionary with the response\n",
        "\n",
        "\n",
        "  def predict(self, prompt): # Define a predict method (kept for backward compatibility)\n",
        "    response_list = [\n",
        "        'islamabad is the capital of Pakistan',\n",
        "        'PSL is a cricket league',\n",
        "        'AI stands for Artificial Intelligence'\n",
        "    ]\n",
        "\n",
        "    return {'response': random.choice(response_list)} # Return a dictionary with the response"
      ],
      "metadata": {
        "id": "1q8AMHn_08-k"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NakliPromptTemplate(Runnable): # Define NakliPromptTemplate inheriting from Runnable\n",
        "\n",
        "  def __init__(self, template, input_variables):\n",
        "    self.template = template # Store the template string\n",
        "    self.input_variables = input_variables # Store the list of input variables\n",
        "\n",
        "  def invoke(self, input_dict): # Implement the invoke method\n",
        "    return self.template.format(**input_dict) # Format the template with the input dictionary\n",
        "\n",
        "  def format(self, input_dict): # Define a format method (kept for backward compatibility)\n",
        "    return self.template.format(**input_dict) # Format the template with the input dictionary"
      ],
      "metadata": {
        "id": "Fh8JKXai1NwO"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NakliStrOutputParser(Runnable): # Define a simple mock OutputParser inheriting from Runnable\n",
        "\n",
        "  def __init__(self):\n",
        "    pass # No initialization needed\n",
        "\n",
        "  def invoke(self, input_data): # Implement the invoke method\n",
        "    return input_data['response'] # Extract and return the 'response' from the input dictionary"
      ],
      "metadata": {
        "id": "Qrx59hyj-AOv"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RunnableConnector(Runnable): # Define a class to connect multiple Runnables\n",
        "\n",
        "  def __init__(self, runnable_list):\n",
        "    self.runnable_list = runnable_list # Store the list of Runnables\n",
        "\n",
        "  def invoke(self, input_data): # Implement the invoke method\n",
        "\n",
        "    for runnable in self.runnable_list: # Iterate through the list of Runnables\n",
        "      input_data = runnable.invoke(input_data) # Invoke each Runnable and pass the output as input to the next\n",
        "\n",
        "    return input_data # Return the final output"
      ],
      "metadata": {
        "id": "fZKQ4oED3i1f"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = NakliPromptTemplate( # Create an instance of NakliPromptTemplate\n",
        "    template='Write a {length} poem about {topic}', # Define the template string\n",
        "    input_variables=['length', 'topic'] # Define the input variables\n",
        ")"
      ],
      "metadata": {
        "id": "MEz_6YHN400i"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = NakliLLM() # Create an instance of NakliLLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8hKZtLn2OZl",
        "outputId": "ae40012f-a1fe-4cda-95cd-198a99fbb77f"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = NakliStrOutputParser() # Create an instance of NakliStrOutputParser"
      ],
      "metadata": {
        "id": "GP8it_Ad-jMX"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RunnableConnector([template, llm, parser]) # Create a RunnableConnector chain"
      ],
      "metadata": {
        "id": "YcXZzkb04TIc"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'length':'long', 'topic':'Pakistan'}) # Invoke the chain with specific inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8ZLxzDvf5NyM",
        "outputId": "88dbc471-8c6a-4a49-ce6d-5cb9b8cd21ca"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PSL is a cricket league'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template1 = NakliPromptTemplate( # Create another instance of NakliPromptTemplate\n",
        "    template='Write a joke about {topic}', # Define the template string\n",
        "    input_variables=['topic'] # Define the input variable\n",
        ")"
      ],
      "metadata": {
        "id": "nDapvS09_UNh"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template2 = NakliPromptTemplate( # Create another instance of NakliPromptTemplate\n",
        "    template='Explain the following joke {response}', # Define the template string\n",
        "    input_variables=['response'] # Define the input variable\n",
        ")"
      ],
      "metadata": {
        "id": "qrj68ALF_jxD"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = NakliLLM() # Create another instance of NakliLLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaPOsPis_ylw",
        "outputId": "9c7ea4ba-82bf-42d0-ebef-1f4aa0d3004f"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = NakliStrOutputParser() # Create another instance of NakliStrOutputParser"
      ],
      "metadata": {
        "id": "O1qfmttN_0aq"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = RunnableConnector([template1, llm]) # Create the first chain with template1 and llm"
      ],
      "metadata": {
        "id": "9mJujzUMACnJ"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1.invoke({'topic':'pakistan'}) # Invoke the first chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfl1yZMVAR_s",
        "outputId": "2e938ef0-bc32-4da7-9558-b1bc35072edc"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': 'PSL is a cricket league'}"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = RunnableConnector([template2, llm, parser]) # Create the second chain with template2, llm, and parser"
      ],
      "metadata": {
        "id": "xnWiCv1CBphh"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain = RunnableConnector([chain1, chain2]) # Create a final chain by connecting chain1 and chain2"
      ],
      "metadata": {
        "id": "iYSdyqKEBse0"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain.invoke({'topic':'cricket'}) # Invoke the final chain with a specific input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-WizhjAvB2d0",
        "outputId": "dc37b00e-f041-426e-a301-507e992ae6ba"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AI stands for Artificial Intelligence'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    }
  ]
}
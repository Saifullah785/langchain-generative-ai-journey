{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d229a0",
   "metadata": {},
   "source": [
    "# 1. **Runnable Sequence**\n",
    "\n",
    "\n",
    "RunnableSequence is a Sequential chain of runnables in langchain that executes each step one after another, passing the output of one step as the input to the next.\n",
    "\n",
    "it is useful when you need to compose multiple runnables together in a structured workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd012f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules for HuggingFace LLM, prompt templates, output parsing, environment variables, and runnable chains.\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e9b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HuggingFaceEndpoint with the Meta-Llama model for text generation.\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id ='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "    task = 'text-generation'\n",
    ")\n",
    "\n",
    "# Wrap the endpoint in a ChatHuggingFace object for chat-style interaction.\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90278a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string output parser to extract plain text from the model's response.\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template to generate a joke about a given topic.\n",
    "prompt1 = PromptTemplate(\n",
    "    template='write a joke about {topic}',\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f07f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template to explain a given joke.\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"Explain the following joke - {text}\",\n",
    "    input_variables= ['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a runnable sequence chain that generates a joke, then explains it.\n",
    "chain = RunnableSequence(prompt1, model, parser, prompt2, model, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9385eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This joke is a play on words, combining a common phrase related to weight loss with a term from computer science.\n",
      "\n",
      "In the context of the joke, \"lose some bytes\" is a pun. In computer science, a \"byte\" is a unit of digital information, equivalent to 8 bits. It's a fundamental concept in programming and data storage.\n",
      "\n",
      "The phrase \"lose some weight\" is a common idiom used in the context of dieting, implying that someone wants to reduce their body weight.\n",
      "\n",
      "In the joke, the AI program is said to \"lose some bytes,\" which is a clever play on words, as it connects the concept of digital information (bytes) with the idea of weight loss (losing weight). The punchline is a clever and humorous connection between the two concepts.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain with the topic \"AI\" and print the explanation of the generated joke.\n",
    "print(chain.invoke({'topic':'AI'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c26d1",
   "metadata": {},
   "source": [
    "# 2. **RunnableParallel**\n",
    "\n",
    "RunnableParallel is a runnable primitive that allow multiple runnables to execute in parallel.\n",
    "\n",
    "Each runnable receives the same input and processes it independently, producing a dictionary of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecf0779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules for parallel chains, prompt templates, output parsing, and environment variables.\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema.runnable import RunnableSequence, RunnableParallel\n",
    "\n",
    "# Load environment variables (such as API keys) from a .env file.\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e0ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HuggingFaceEndpoint and wrap it in a ChatHuggingFace model for text generation.\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id ='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "    task = 'text-generation'\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb5334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string output parser to extract plain text from the model's response.\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template to generate a tweet about a given topic.\n",
    "prompt1 = PromptTemplate(\n",
    "    template= \"Generate a tweet about {topic}\",\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8978403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template to generate a Linkedin post about a given topic.\n",
    "prompt2 = PromptTemplate(\n",
    "    template = 'Generate a Linkedin post about {topic}',\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4016ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a parallel chain that generates both a tweet and a Linkedin post in parallel.\n",
    "parallel_chain = RunnableParallel({\n",
    "    'tweet' : RunnableSequence (prompt1, model, parser),\n",
    "    'linkedin' : RunnableSequence (prompt2, model, parser)\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a0695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The future is here and it's coded. Artificial Intelligence is revolutionizing the way we live, work, and interact. What's the next innovation that AI will bring to the table? #ArtificialIntelligence #AI #FutureTech\"\n",
      "**The Future of Work: How AI is Revolutionizing Industries**\n",
      "\n",
      "As we continue to navigate the ever-evolving landscape of technology, one thing is clear: Artificial Intelligence (AI) is no longer a novelty, but a fundamental aspect of our professional lives.\n",
      "\n",
      "From automating mundane tasks to enhancing decision-making capabilities, AI is transforming industries and shaping the future of work. Whether you're a seasoned executive or a young professional, it's essential to stay ahead of the curve and understand the implications of AI on your career.\n",
      "\n",
      "Here are just a few ways AI is impacting the world of work:\n",
      "\n",
      " **Increased Efficiency**: AI can automate repetitive tasks, freeing up time for more strategic and creative work.\n",
      "\n",
      " **Enhanced Decision-Making**: AI-powered tools can analyze vast amounts of data, providing insights that inform decision-making and drive business growth.\n",
      "\n",
      " **Improved Customer Experience**: AI-driven chatbots and virtual assistants are revolutionizing the way we interact with customers, providing personalized support and improving overall satisfaction.\n",
      "\n",
      "As AI continues to advance, it's essential to develop the skills necessary to thrive in this new landscape. Whether it's learning to work with AI tools, developing data analysis skills, or understanding the ethics of AI, there has never been a more exciting time to be in the workforce.\n",
      "\n",
      "**What do you think about the future of work and AI? Share your thoughts and experiences in the comments below!**\n",
      "\n",
      "**#AI #FutureOfWork #Innovation #CareerDevelopment #Technology #Productivity**\n"
     ]
    }
   ],
   "source": [
    "# Invoke the parallel chain with the topic \"AI\" and print both the tweet and Linkedin post.\n",
    "result = parallel_chain.invoke({'topic': 'AI'})\n",
    "\n",
    "print(result['tweet'])\n",
    "\n",
    "print(result['linkedin'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f29db",
   "metadata": {},
   "source": [
    "# **3. Runnable Passthrough\n",
    "\n",
    "Runnable Passthrough is a special Runnable perimitive that simply returns the output as output without modifying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069ae18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules for passthrough, prompt templates, output parsing, and environment variables.\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "from langchain.schema.runnable import RunnableSequence, RunnableParallel,RunnablePassthrough\n",
    "# Load environment variables (such as API keys) from a .env file.\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Saifullah'}\n"
     ]
    }
   ],
   "source": [
    "# Create a passthrough runnable that returns the input as output.\n",
    "passthrough = RunnablePassthrough()\n",
    "\n",
    "\n",
    "# Test the passthrough by passing a dictionary and printing the result.\n",
    "print(passthrough.invoke({'name': 'Saifullah'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HuggingFaceEndpoint and wrap it in a ChatHuggingFace model for text generation.\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id ='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "    task = 'text-generation'\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbcb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string output parser to extract plain text from the model's response.\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template to generate a joke about a given topic.\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template='write a joke about {topic}',\n",
    "    input_variables=['topic']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template to explain a given joke.\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"Explain the following joke - {text}\",\n",
    "    input_variables= ['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a runnable sequence chain that generates a joke.\n",
    "\n",
    "joke_gen_chain = RunnableSequence(prompt1, model, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7224b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a parallel chain that passes the joke through and also generates an explanation for it.\n",
    "parallel_chain = RunnableParallel({\n",
    "    'joke': RunnablePassthrough(),\n",
    "    'explanation' : RunnableSequence(prompt2, model, parser)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the joke generation and parallel explanation into a final chain.\n",
    "\n",
    "final_chain = RunnableSequence(joke_gen_chain, parallel_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': 'Why did the volleyball player bring a ladder to the game?\\n\\nBecause she wanted to take her game to the next level! (get it?)', 'explanation': 'This joke uses a play on words to create the pun. The phrase \"take it to the next level\" is a common idiomatic expression used to convey improvement or advancement in a particular skill or field. \\n\\nIn this joke, the volleyball player takes the phrase literally by bringing a ladder, which is a physical object that allows someone to climb to a higher level. The humor comes from the unexpected twist on the usual meaning of the phrase, creating a clever and silly connection between the volleyball game and the physical ladder. The punchline relies on the dual meaning of \"next level\" to create the comedic effect.'}\n"
     ]
    }
   ],
   "source": [
    "# Invoke the final chain with the topic \"vollyball\" and print both the joke and its explanation.\n",
    "print(final_chain.invoke({'topic': 'vollyball'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7b6e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
